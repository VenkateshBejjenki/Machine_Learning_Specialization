{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# implemenation of KNN alogorithm\n",
    "pre processing the training dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'attachments/trainProdSelection.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-543b0e263dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attachments/trainProdSelection.arff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'attachments/trainProdSelection.arff'"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import math\n",
    "df=arff.load(open('attachments/trainProdSelection.arff','rb'))\n",
    "train=df['data']\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre processing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'attachments/testProdSelection.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-031b21e8648a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attachments/testProdSelection.arff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'attachments/testProdSelection.arff'"
     ]
    }
   ],
   "source": [
    "df1=arff.load(open('attachments/testProdSelection.arff','rb'))\n",
    "test=df1['data']\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the attributes in the trainig dataset for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting attributes\n",
    "typ=[]\n",
    "ls=[]\n",
    "vac=[]\n",
    "ec=[]\n",
    "sal=[]\n",
    "prp=[]\n",
    "lab=[]\n",
    "for i in range(len(train)):\n",
    "    typ.append(train[i][0])\n",
    "    ls.append(train[i][1])\n",
    "    vac.append(train[i][2])\n",
    "    ec.append(train[i][3])\n",
    "    sal.append(train[i][4])\n",
    "    prp.append(train[i][5])\n",
    "    lab.append(train[i][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalizing numeric values of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing numeric values of train data\n",
    "maxx=max(vac)\n",
    "minn=min(vac)\n",
    "for i in range(len(vac)):\n",
    "    vac[i]=(vac[i]-minn)/(maxx-minn)\n",
    "maxx=max(ec)\n",
    "minn=min(ec)\n",
    "for i in range(len(ec)):\n",
    "    ec[i]=(ec[i]-minn)/(maxx-minn)\n",
    "maxx=max(sal)\n",
    "minn=min(sal)\n",
    "for i in range(len(sal)):\n",
    "    sal[i]=(sal[i]-minn)/(maxx-minn)\n",
    "maxx=max(prp)\n",
    "minn=min(prp)\n",
    "for i in range(len(prp)):\n",
    "    prp[i]=(prp[i]-minn)/(maxx-minn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  splitting and  normalizing the attributes in the testing dataset for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing numeric values of test data\n",
    "typ1=[]\n",
    "ls1=[]\n",
    "vac1=[]\n",
    "ec1=[]\n",
    "sal1=[]\n",
    "prp1=[]\n",
    "lab1=[]\n",
    "for i in range(len(test)):\n",
    "    typ1.append(test[i][0])\n",
    "    ls1.append(test[i][1])\n",
    "    vac1.append(test[i][2])\n",
    "    ec1.append(test[i][3])\n",
    "    sal1.append(test[i][4])\n",
    "    prp1.append(test[i][5])\n",
    "    lab1.append(test[i][6])\n",
    "maxx=max(vac1)\n",
    "minn=min(vac1)\n",
    "for i in range(len(vac1)):\n",
    "    vac1[i]=(vac1[i]-minn)/(maxx-minn)\n",
    "maxx=max(ec1)\n",
    "minn=min(ec1)\n",
    "for i in range(len(ec1)):\n",
    "    ec1[i]=(ec1[i]-minn)/(maxx-minn)\n",
    "maxx=max(sal1)\n",
    "minn=min(sal1)\n",
    "for i in range(len(sal1)):\n",
    "    sal1[i]=(sal1[i]-minn)/(maxx-minn)\n",
    "maxx=max(prp1)\n",
    "minn=min(prp1)\n",
    "for i in range(len(prp1)):\n",
    "    prp1[i]=(prp1[i]-minn)/(maxx-minn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the euclidean distance by using simmilarity matrix .sorting and finding the top  closest vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0695083253048292, 0, 0.5347541626524146, 0, 0], [1.5983556661217126, 0, 0, 0, 0], [1.659158441296079, 0, 0, 0, 0], [1.8405040396420111, 0, 0, 0, 0], [0, 1.6694244203291024, 0, 0, 0], [0, 1.6402615744252724, 0, 0, 0], [0, 1.7987938573531799, 0, 0, 0], [0, 1.6807444495427126, 0, 0, 0], [0, 0, 1.8650768534891249, 0, 0], [0, 0, 1.8676818366369126, 0, 0], [0, 0, 1.5186008292035151, 0, 0], [0, 0, 1.4547377254493692, 0, 0], [0, 0, 0, 0, 1.7406869027077345], [0, 0, 0, 1.89213933234292, 0], [1.2023303370790301, 0, 0, 0.6011651685395151, 0], [1.218451897298994, 0, 0, 0.609225948649497, 0], [0, 0, 0, 1.2125862146487187, 0.6062931073243594], [0, 0, 0, 1.1414072499185028, 0.5707036249592514], [0, 0, 0, 0, 1.6633684030915807], [0, 0, 0, 0, 1.6955003770069013], [0, 0, 0, 0, 1.6850987615790298]]\n"
     ]
    }
   ],
   "source": [
    "output=[]\n",
    "for i in range(len(test)):\n",
    "    list1=[]\n",
    "    for j in range(0,len(train)):\n",
    "        v=((vac1[i]-vac[j])**2)+((ec1[i]-ec[j])**2)+((sal1[i]-sal[j])**2)+((prp1[i]-prp[j])**2)\n",
    "        if(typ1[i]!=typ[j]):\n",
    "            v=v+1;\n",
    "        if(ls1[i]!=ls[j]):\n",
    "            v=v+1;\n",
    "        eScore=1/math.sqrt(v)\n",
    "        list2=[]\n",
    "        list2.append(eScore)\n",
    "        list2.append(lab[j])\n",
    "        list1.append(list2)\n",
    "    list1=sorted(list1,key=lambda x:x[0])\n",
    "    temp=[0,0,0,0,0]\n",
    "    for j in range(len(list1)-3,len(list1)):\n",
    "        temp[int(list1[j][1][1])-1]=temp[int(list1[j][1][1])-1]+list1[i][0]\n",
    "    output.append(temp)\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## calculating the performance metirc of the given dataset .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "28.5714285714\n"
     ]
    }
   ],
   "source": [
    "#performance metric\n",
    "count=0\n",
    "for i in range(len(output)):\n",
    "    maxx=output[i][0]\n",
    "    imax=0\n",
    "    for j in range(1,len(output[i])):\n",
    "        if(output[i][j]>maxx):\n",
    "#             print \"hi\"\n",
    "            maxx=output[i][j]\n",
    "            imax=j\n",
    "    imax=imax+1\n",
    "    if(int(lab1[i][1])==imax):\n",
    "#         print \"hi\"\n",
    "        count=count+1\n",
    "print count\n",
    "acc=(count/(len(test)*1.0))*100\n",
    "print acc"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
